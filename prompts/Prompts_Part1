Act as a Senior Data Engineer specializing in Python and data quality automation.

Task: Develop a production-ready Python script to clean and audit a dataset.

Context: I have a CSV file named data.csv with three columns: Audit_ID, Status, and Risk_Score. The Risk_Score column is dirty, containing numeric values, text (e.g., "error_reading", "ninety"), and nulls.
Requirements:

Data Cleaning: Load the CSV using pandas. Clean the Risk_Score column by converting all non-numeric values (including text and formatting errors) to NaN or 0. Ensure the final type for this column is numeric.
Flagging Logic: Create a new boolean column named High_Risk_Flag. A record must be flagged (True) only if the Status is exactly "Fail" and the Risk_Score is strictly greater than 80.
Use modular programming (define clear functions for loading, cleaning, and processing).
Incorporate logging to track the process (avoid using simple print statements).
Use Type Hinting for function signatures.
Include basic error handling (e.g., check if the file exists).
Follow PEP 8 standards.
Outputs: 
1. The complete Python script.
2. A brief explanation of the cleaning strategy used for the Risk_Score column.

Take in account the Execution Flow of the project:
-Raw CSV is placed in src/data/
-audits_cleaner.py reads the file
-Data cleaning and transformation are performed
-Results are written into src/output/

